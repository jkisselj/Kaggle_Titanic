{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71215b16-4307-4b48-beb3-2f8e548447f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ячейка 1: Загрузка 'чистых' данных...\n",
      "Размер Train: (891, 12)\n",
      "Размер Test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -- 1. ЗАГРУЗКА ДАННЫХ --\n",
    "print(\"Ячейка 1: Загрузка 'чистых' данных...\")\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Сохраняем PassengerId для файла отправки\n",
    "test_passenger_ids = test_df['PassengerId']\n",
    "\n",
    "# ВАЖНО: Мы НЕ объединяем их здесь. \n",
    "# Мы будем обрабатывать train и test отдельно, но ОДИНАКОВО.\n",
    "print(f\"Размер Train: {train_df.shape}\")\n",
    "print(f\"Размер Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7fd8972-e50c-4ad1-9c69-9dafa42322f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шаг 1: Создание 'FamilySize'...\n",
      "--- Распределение FamilySize ---\n",
      "FamilySize\n",
      "1     537\n",
      "2     161\n",
      "3     102\n",
      "4      29\n",
      "6      22\n",
      "5      15\n",
      "7      12\n",
      "11      7\n",
      "8       6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Шаг 2: Создание 'IsAlone'...\n",
      "--- Распределение IsAlone (1 = Одинок, 0 = Есть семья) ---\n",
      "IsAlone\n",
      "1    537\n",
      "0    354\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- ГИПОТЕЗА 2: Фича \"FamilySize\" (Размер Семьи) ---\n",
    "print(\"Шаг 1: Создание 'FamilySize'...\")\n",
    "\n",
    "# Мы просто складываем колонки, как обычные числа\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "# --- Проверяем, что получилось ---\n",
    "print(\"--- Распределение FamilySize ---\")\n",
    "print(train_df['FamilySize'].value_counts())\n",
    "\n",
    "# --- ГИПОТЕЗА 3: Фича \"IsAlone\" (Одиночка) ---\n",
    "print(\"\\nШаг 2: Создание 'IsAlone'...\")\n",
    "\n",
    "# \"Рецепт\" в 1 строку:\n",
    "# 1. (train_df['FamilySize'] == 1) - эта часть создает колонку из True/False\n",
    "# 2. .astype(int) - эта часть превращает True в 1 и False в 0\n",
    "train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)\n",
    "test_df['IsAlone'] = (test_df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# --- Проверяем, что получилось ---\n",
    "print(\"--- Распределение IsAlone (1 = Одинок, 0 = Есть семья) ---\")\n",
    "print(train_df['IsAlone'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a974b1a3-eb7a-4b97-8d03-172ace2b40a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ячейка 2: Запуск ЕДИНОГО блока предобработки...\n",
      "Создание 'Title'...\n",
      "Создание 'FamilySize' и 'IsAlone'...\n",
      "Создание 'Deck'...\n",
      "Заполнение пропусков в 'Age', 'Fare', 'Embarked'...\n",
      "Финальное кодирование (get_dummies)...\n",
      "\n",
      "--- ПРЕДОБРАБОТКА ЗАВЕРШЕНА ---\n",
      "Колонки в X_train: (891, 22)\n",
      "Колонки в X_test: (418, 22)\n",
      "Колонки в y_train: (891,)\n"
     ]
    }
   ],
   "source": [
    "# --- ЕДИНЫЙ БЛОК ПРЕДОБРАБОТКИ (Гипотезы 1-5) ---\n",
    "print(\"\\nЯчейка 2: Запуск ЕДИНОГО блока предобработки...\")\n",
    "\n",
    "# -- Создаем копии, чтобы избежать \"SettingWithCopyWarning\"\n",
    "# Мы работаем с train_data и test_data\n",
    "train_data = train_df.copy()\n",
    "test_data = test_df.copy()\n",
    "\n",
    "# --- ГИПОТЕЗА 1: Фича \"Title\" (Титул) ---\n",
    "print(\"Создание 'Title'...\")\n",
    "# Шаг 1: Извлечение\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "# Шаг 2: Очистка\n",
    "train_data['Title'] = train_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "train_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n",
    "test_data['Title'] = test_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "test_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\n",
    "rare_titles = ['Dr', 'Rev', 'Col', 'Major', 'Don', 'Lady', 'Sir', 'Capt', 'Countess', 'Jonkheer', 'Dona']\n",
    "train_data['Title'] = train_data['Title'].replace(rare_titles, 'Rare')\n",
    "test_data['Title'] = test_data['Title'].replace(rare_titles, 'Rare')\n",
    "# Заполняем 1 пропуск в test_data (если вдруг появился)\n",
    "test_data['Title'] = test_data['Title'].fillna('Rare')\n",
    "\n",
    "\n",
    "# --- ГИПОТЕЗА 2 и 3: \"FamilySize\" и \"IsAlone\" ---\n",
    "print(\"Создание 'FamilySize' и 'IsAlone'...\")\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "train_data['IsAlone'] = (train_data['FamilySize'] == 1).astype(int)\n",
    "test_data['IsAlone'] = (test_data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# --- ГИПОТЕЗА 4: \"Deck\" (Палуба) ---\n",
    "print(\"Создание 'Deck'...\")\n",
    "train_data['Deck'] = train_data['Cabin'].fillna('U').str[0]\n",
    "test_data['Deck'] = test_data['Cabin'].fillna('U').str[0]\n",
    "\n",
    "# --- ГИПОТЕЗА 5: Заполнение пропусков (Age, Fare, Embarked) ---\n",
    "print(\"Заполнение пропусков в 'Age', 'Fare', 'Embarked'...\")\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "\n",
    "# --- УДАЛЕНИЕ \"МУСОРНЫХ\" КОЛОНОК ---\n",
    "# Мы удаляем их ДО кодирования\n",
    "drop_cols = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n",
    "train_data = train_data.drop(columns=drop_cols)\n",
    "test_data = test_data.drop(columns=drop_cols)\n",
    "\n",
    "# ---  Кодирование (One-Hot Encoding) ---\n",
    "print(\"Финальное кодирование (get_dummies)...\")\n",
    "categorical_features = ['Title', 'Deck', 'Sex', 'Embarked']\n",
    "# Мы используем pd.concat, чтобы \"взорвать\" ОБА датасета ОДИНАКОВО\n",
    "full_data = pd.concat([train_data, test_data], axis=0)\n",
    "full_data_dummies = pd.get_dummies(full_data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Разделяем обратно\n",
    "X_train = full_data_dummies.iloc[:len(train_data)]\n",
    "X_test = full_data_dummies.iloc[len(train_data):]\n",
    "y_train = train_data['Survived'] # Берем 'Survived' из train_data (до \"взрыва\")\n",
    "\n",
    "# УДАЛЯЕМ 'Survived' из X_train\n",
    "X_train = X_train.drop('Survived', axis=1)\n",
    "X_test = X_test.drop('Survived', axis=1)\n",
    "\n",
    "print(\"\\n--- ПРЕДОБРАБОТКА ЗАВЕРШЕНА ---\")\n",
    "print(\"Колонки в X_train:\", X_train.shape)\n",
    "print(\"Колонки в X_test:\", X_test.shape)\n",
    "print(\"Колонки в y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff25383-f734-4daf-958a-85b2a2efe760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ячейка 3: Запуск обучения...\n",
      "Данные отмасштабированы (StandardScaler).\n",
      "Модель RandomForest (ЧЕМПИОН) ОБУЧЕНА!\n",
      "\n",
      "--- ФИНАЛЬНЫЙ ФАЙЛ 'submission_FINAL_789.csv' СОЗДАН! ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Ячейка 3: Обучение Модели и Отправка ---\n",
    "print(\"\\nЯчейка 3: Запуск обучения...\")\n",
    "\n",
    "# --- ШАГ 1: Масштабирование (StandardScaler) ---\n",
    "# Мы \"кормим\" StandardScaler нашими \"умными\" фичами\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Данные отмасштабированы (StandardScaler).\")\n",
    "\n",
    "# --- ШАГ 2: Обучение \"Чемпионской\" Модели ---\n",
    "# Мы используем RandomForest (который дал 78.5%)\n",
    "# И \"лечим\" переобучение с помощью max_depth=5\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,            \n",
    "    min_samples_leaf=3,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Модель RandomForest (ЧЕМПИОН) ОБУЧЕНА!\")\n",
    "\n",
    "# --- ШАГ 3: Создание файла для Kaggle ---\n",
    "predictions = model.predict(X_test_scaled).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Сохраняем финальный файл\n",
    "submission.to_csv('submission_FINAL_789.csv', index=False)\n",
    "print(\"\\n--- ФИНАЛЬНЫЙ ФАЙЛ 'submission_FINAL_789.csv' СОЗДАН! ---\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06476d-019d-4b56-947d-209a2d845b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfbde9-bb9f-4d5f-bff0-a7d5d08a0341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f9c29-bf84-449d-94dc-21c39c3174f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543e17b-09a4-41d8-a765-90b0ae8f6c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (titanic_project)",
   "language": "python",
   "name": "titanic_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
